# ai_responses.py
import openai
import google.generativeai as genai
from config import OPENAI_API_KEY, GEMINI_API_KEY, RADIO_JAVAN_ACCESS_KEY
import requests

# Configure OpenAI
openai.api_key = OPENAI_API_KEY

# Configure Gemini
genai.configure(api_key=GEMINI_API_KEY)
gemini_model = genai.GenerativeModel('gemini-pro')

def get_ai_response(user_message: str, user_id: int) -> str:
    """Generates a general AI response using OpenAI or Gemini, personalized for Behnoush."""
    # Use OpenAI for general conversation
    try:
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=f"ฺฉุงุฑุจุฑ: {user_message}\nุฑุจุงุช (ุจุง ูุญู ููุฑุจุงู ู ุฏูุณุชุงููุ ุจู ูุงุฑุณ ู ุจุง ุฎุทุงุจ 'ุจูููุด ุฌุงู' ุงฺฏุฑ ูุงู ฺฉุงุฑุจุฑ ุจูููุด ุงุณุช):",
            max_tokens=100,
            temperature=0.7,
            stop=["\n"]
        )
        ai_text = response.choices[0].text.strip()
        return ai_text

    except Exception as e:
        print(f"OpenAI Error: {e}")
        return "ุจูููุด ุฌุงูุ ูุชุงุณูุงูู ุงูุงู ููโุชููู ุจูุช ูพุงุณุฎ ุจุฏู. ู ูุดฺฉู ฺฉูฺฺฉ ูพุด ุงููุฏู. ๐"

def search_music(query: str) -> str:
    """Search for music using Radio Javan API."""
    API_URL = "https://api.ineo-team.ir/rj.php"
    params = {
        'accessKey': RADIO_JAVAN_ACCESS_KEY,
        'action': 'search',
        'query': query
    }
    
    try:
        response = requests.post(API_URL, data=params)
        result = response.json()
        
        if result['status_code'] == 200:
            music_results = result['result']
            if music_results:
                response_text = "ูุชุงุฌ ุฌุณุชุฌู:\n"
                for i, music in enumerate(music_results[:3]):  # Limit to 3 results
                    title = music.get('title', 'Unknown Title')
                    artist = music.get('artist', 'Unknown Artist')
                    response_text += f"{i + 1}. {title} - {artist}\n"
                return response_text
            else:
                return "ูุชุงุณูุงูู ูฺ ูุชุฌูโุง ูพุฏุง ูุดุฏ."
        else:
            return "ุจูููุด ุฌุงูุ ูุชุงุณูุงูู ุฏุฑ ุฌุณุชุฌู ูุดฺฉู ูพุด ุขูุฏู ุงุณุช."

    except Exception as e:
        print(f"Radio Javan API Error: {e}")
        return "ุจูููุด ุฌุงูุ ูุชุงุณูุงูู ุฏุฑ ุญุงู ุญุงุถุฑ ููโุชููู ุจูุช ฺฉูฺฉ ฺฉูู. ูุทูุง ุจุนุฏุง ุงูุชุญุงู ฺฉู."

def get_joke() -> str:
    """Generates a joke using OpenAI or a predefined list."""
    jokes = [
        "ฺุฑุง ฺฉุงููพูุชุฑ ุขูุณุชู ฺฉุงุฑ ูโฺฉุฑุฏุ ฺูู ุฑู ฺฉุงููพูุชุฑ ุฎูุงุจุด ูููุฏ!",
        "ุขูุง ู ุชูุณุงุญ ฺุทูุฑ ุชุงุจุณุชูู ุฑู ูโฺฏุฐุฑูููุ ุจุง ฺฉููุฑ ฺฉุฑูฺฉูุฏู!",
        "ูโุฏูู ฺุฑุง ุฏุงูุดุฌููุง ุณุงูุฏูฺ ุฏูุณุช ุฏุงุฑูุฏุ ฺูู ู ุฑูุฒ ู ุงุณุชุงุฏ ฺฏูุช: ูุฑ ฺฉ ุชฺฉููุด ุฑู ูุฏู ุณุงูุฏูฺ ูุดู!",
        "ุจูููุด ุฌุงูุ ูโุฏูู ฺุฑุง ูฺฉโูฺฉโูุง ูููุน ุฎูุงุจ ู ูพุงุดูู ุฑู ุจุงูุง ูฺฏู ูโุฏุงุฑูุ ฺูู ุงฺฏู ูุฑ ุฏู ูพุงุดูู ุฑู ุจุฐุงุฑู ุฒููุ ูโุงูุชู! ๐"
    ]
    
    try:
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt="ู ุฌูฺฉ ฺฉูุชุงู ู ุจุงูุฒู ุจู ูุงุฑุณ ุจฺฏู:",
            max_tokens=50,
            temperature=0.8
        )
        joke = response.choices[0].text.strip()
        return joke
    except Exception as e:
        print(f"OpenAI Joke Error: {e}")
        import random
        return random.choice(jokes)

def get_supportive_message() -> str:
    """Generates a supportive message using Gemini or a predefined list."""
    supportive_messages = [
        "ุชู ุฎู ููโุชุฑ ุงุฒ ุงู ุญุฑูุง! ูโุฏููู ูโุชูู ุงุฒ ูพุณ ูุฑ ฺุฒ ุจุฑุจุง.",
        "ุจุฏูู ฺฉู ูุฑ ุฑูุฒ ู ูุฏู ุจู ุจูุชุฑ ุดุฏู ูุฒุฏฺฉโุชุฑ ูุดุ ูู ููุดู ุงูุฌุง ูุณุชู ุจุฑุงุช.",
        "ุฒูุฏฺฏ ูุซู ู ุฌุนุจู ุดฺฉูุงุชูุ ุดุงุฏ ุจุนุถ ููุงูุน ูุฒูโุงุด ุฑู ูููู ุงูุง ูููุฒ ุดฺฉูุงุชโูุง ุฎูุดูุฒู ุฒุงุฏ ูููุฏู!",
        "ุงุฏุช ุจุงุดู ุจูููุด ุฌุงูุ ุจุนุฏ ุงุฒ ูุฑ ุณุฎุชุ ุขุณุงู ูุณุช. ูู ุจูุช ุงูุงู ุฏุงุฑู! ๐",
        "ุจูููุด ุนุฒุฒูุ ูุจุฎูุฏ ุชู ูุดูฺฏโุชุฑู ฺุฒู ฺฉู ูโุชููู ุจุจูู. ุงูุฏูุงุฑู ุฒูุฏุชุฑ ุญุงูุช ุฎูุจ ุจุดู."
    ]
    
    try:
        response = gemini_model.generate_content(
            "ฺฉ ูพุงู ฺฉูุชุงูุ ูุซุจุช ู ุงูุฏุจุฎุด ุจู ูุงุฑุณ ุจุฑุง ฺฉุณ ฺฉู ฺฉู ูุงุฑุงุญุช ุงุณุชุ ุจุง ุฎุทุงุจ 'ุจูููุด ุฌุงู' ุจููุณ:",
            generation_config=genai.types.GenerationConfig(
                temperature=0.9,
                max_output_tokens=80,
            )
        )
        message = response.text.strip()
        return message
    except Exception as e:
        print(f"Gemini Supportive Message Error: {e}")
        import random
        return random.choice(supportive_messages)
